안녕하십니까
스테이츠 연구소 주임연구원 박병찬입니다.

금일 소개드릴 모델은 이미지 속 문자를 디지털화하는 광학 문자인식
OCR 모델입니다.

------------------------------------------------------------------------------------------

목차로는
주제소개,
OCR모델에 대하여
모델비교
회고 순으로 진행하겠습니다.

------------------------------------------------------------------------------------------

여러분들 모두 회원가입시에 reCaptcha라는 프로그램을 만나보신적이 있으실텐데요,
이는 투표수 조작, 스팸메일 방지 등 봇들의 역할수행으로 인해 피해를 줄일 수 있도록
사이트에 접속을 시도한 주체가 사람인지 봇인지 필터링하기 위해서 탄생하였습니다.

그런데 이 사진이 대체 어떤 역할을 하기에 컴퓨터는 읽을 수 없는걸까요?

------------------------------------------------------------------------------------------

단순 몇줄의 노이즈 때문에, 컴퓨터가 명확히 판단하기 어려운걸까요?

------------------------------------------------------------------------------------------

아니면 색맹인 사람들에게 특정 그림이 보이지 않듯 컴퓨터가 이미지를 아예 보질 못하는걸까요?

------------------------------------------------------------------------------------------

사실 이보다 더 간단하게, 0과 1을 처리하는 컴퓨터에게 비정형데이터인 이미지는
"몇가지 글자를 품고 있던 상관 없이",
"그림"이라는 한가지로 인식되기 때문에, 학습된 모델이 내제되어있지 않은 컴퓨터에겐
단순히 그림을 멀뚱멀뚱 쳐다보고 있는 것입니다.

비유를하자면
교양이 상대적으로 부족한 일반인은
아무리 뛰어난 화가의 그림을 본다 한들, 해석을 하지 못하고
바라만보는 느낌이라고 설명할 수 있겠습니다.

------------------------------------------------------------------------------------------

이말은 즉슨, 이 모델을 내제할 수 있다면,
이 캡챠를 자동으로 pass할 수 있다는 말이 될텐데,
이 가설이 실제로 구현이 가능한지
모델의 오픈소스를 통해 수정해 가며 작동원리를 파악하는 논문 리뷰형식의 발표를 진행하겠습니다.

OCR모델의 구성은 크게 

RNN모델, 

CTC 알고리즘에 있습니다.

------------------------------------------------------------------------------------------

RNN모델부터 알아보겠습니다.
텍스트의 조합인 RECHAPTCH 에서는 CNN만으로 글자들의 융합을 유추해 낼 수 없기 때문에

------------------------------------------------------------------------------------------

현재학습과 과거학습의 연결을 시켜줄수 있는 양방향 모델이 필요했고, 그에 적합한 것이 RNN이였습니다.

일부만 보았을땐 L인것 같으나, 주변 정보를 조합 하였을때 M인걸 알 수 있듯 이러한 원리를 적극 활영하여
스펠링 및 숫자 하나하나를 파악할 수 있습니다.

------------------------------------------------------------------------------------------

이렇게 파악된 스펠링 및 숫자들을 조합하는 역할은 CTC알고리즘이 맏습니다..

이미지로부터 어디부터 어디까지 낱개값에 해당하는지 알 수없기 때문에
관계 정렬을 위해 사용됩니다.

자료를 보시면 hello라고 적힌 이미지는 10개로 분할되어 있는데요,
분할된 영역에서 이 이미지가갖는 특징에 대해 
조건부 확률을 계산하여 여러 경우의수를 나열하는데,

------------------------------------------------------------------------------------------

여기서 엡실론은 공백을 의미하며, blank 토큰으로 이미지가 없는 부분은 빈칸으로 처리합니다.

이러한 경우의 수를 종합해 중복된 글자들로 최종 텍스트를 얻어냅니다.

------------------------------------------------------------------------------------------

이 특징을 추출하는 방법은 일련의 filter를 통하는데요,

------------------------------------------------------------------------------------------

이러한 기본 데이터를 주었을 때에는
영상자료와 같이 특징들을 좌측 상단에서부터 우측 하단으로 추출합니다.
한 글자에 대해서 집중해 특징을 뽑아내기 어려워 보입니다.

------------------------------------------------------------------------------------------

따라서
세로로 데이터를 넣어주었을때 
------------------------------------------------------------------------------------------
한 글자에 대해 집중할 수 있는 환경이 조성될것이고, 
이를 토대로 예측결과가 보다 정확할 것이라는 예상이 되었는데요,


------------------------------------------------------------------------------------------
실제로 기본데이터, 
세로데이터, 
세로 반전데이터를 넣어 결과값을 확인 해 보았습니다.

기본데이터의 경우, 정확도가 낮게 보였는데요, unknown을 추출하기도 했습니다.
텍스트의 둥근특징이 있다면 최대한 반영하여 둥근 글자를 매칭해 주긴 하였으나,
정확도가 높지 않았고,
백그라운드에 있는 선까지 특징을 반영한 나머지, 
선이 텍스트와 일체되었다고 생각하는 예측값을 산출했다고 추측이 가능하겠습니다.

------------------------------------------------------------------------------------------

그래프로 보시면, 학습시행횟수는 64회로 추후 나올 두 모델보다 빠르게 완료 되었으나,
틀리게 예측한 경우 오류를 범한 정도인 손실을 보면,
소숫점 자리로의 진입이 어려워 보이며,
이는 곧 소개드릴 두 모델보다 굉장히 높은 수치임을 말씀 드립니다.

즉, 틀리게 예측한 경우 부분점수도 맞기 어려울 만큼 틀렸다.
라고 이해해 주시면 되겠습니다.

------------------------------------------------------------------------------------------

세로형 데이터로 학습시킨 모델들을 비교 해 보겠습니다.

세로데이터입니다.
전처리를 통해 한글자씩 최대한 집중 할 수 있는 환경을 만들어 줘서인지,
대부분의 캡차를 올바르게 유추하는 것을 볼 수 있었습니다.

다음은 세로 반전데이터 입니다.
같은 세로라고 하더라도, 바라보는 방향에 따라 결과값이 달라지는가?
에 따른 의문에서 시도 해 보았는데요, 이 역시 대부분의 캡차를 올바르게 유추하고 있었습니다.

그렇다면 세로 데이터로 학습시킨 모델과 세로반전데이터로 학습시킨 모델의 차이는 어떨까요?

학습시간의 차이가 있습니다.
세로 데이터의 경우 학습 에포크가 100회를 넘겼지만
세로 반전데이터의 경우 학습 에포크가  90 회로
세로 반전데이터를 넣어줬을때 학습속도가 더 빨랐습니다.

틀리게 예측한 경우 오류를 범한 정도인
손실에 대한 결과도 같이 볼 수 있습니다.

------------------------------------------------------------------------------------------

두 모델 모두 0에 수렴하는 값을 보였으나,

------------------------------------------------------------------------------------------
세로 반전데이터가 소숫점 세자리 까지의 loss를 보였었습니다.

세로 회전 반전 데이터는 상대적으로 틀리더라도 그럴듯하게 틀렸다.
라고 받아들일 수 있으나,
loss값이 두 모델 모두 낮은편이기 때문에, 큰 의미는 없을 것 같습니다.


그런데, 이 basic OCR모델의 공식문서를 보면, 세로 데이터를 기반으로 학습시키는 것을 추천하고 있습니다.
정확하진 않지만 그 이유를 추측해보자면,
학습시간에서 시간이 더 걸릴지 라도,
약 1040개의 이미지를 반전시켜야 하는 전처리 시간보단 덜 걸리기 때문인 것으로
직접실시한 전처리 과정에서 유추 할 수 있었습니다.

------------------------------------------------------------------------------------------
결과적으로
세로 반전 데이터가 상대적으로 빨리 학습되며, 그럴듯하게 틀리지만,
전처리 과정이 더 까다롭기 때문에 전체적인 모델의 효율성 면에선
세로 데이터를 사용하는것이 적합하기 때문에
basic모델에서 사용되는 데이터는 세로 데이터이다.
라고 말할 수 있겠습니다.



사실 캡차는 봇을 필터링하기 위한 수단 외에 다른 선기능을 발휘합니다.
바로 라벨링인데요,
서비스 사용자들이 캡차를 입력하며 사람임을 증명하는 과정이
"이 이미지가 갖는 의미가 무엇이다."
라고 알려주는 라벨링의 역할을 하며, 머신러닝계의 중요한 데이터로 축적됩니다.

이를통해 2년만에 옛 서적들 250만부를 디지털화 할수 있었다니, 우리는 머신러닝 발전에 큰 기여를 한 셈입니다.

------------------------------------------------------------------------------------------
 
이제는, 텍스트 형식보다는 신호등을 찾는 등 이미지파일을 선택해야 하는 일이 잦은데요,
이는 자율주행이나, 로드뷰 등에 쓰일 라벨링을 하기 위해 진화된 과정이라고 생각해주시면 될 것 같습니다.

이번 프로젝트에서 부족했던 점은,
독자적인 프로젝트가 아닌 논문리뷰형식으로 진행하게 되어 독창성이 부족하다는 점이 다라고 해도 과언이 아닐 것 같습니다.
추후 나만의 모델을 설계하고 학습시켜 가며 진정 공부와 체득을 하는 시간이 필요할 것이라는 생각을 공유드리며
발표 마치도록 하겠습니다.

